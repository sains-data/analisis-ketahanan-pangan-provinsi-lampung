[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "lampung-food-security"
version = "1.0.0"
description = "Big Data Analytics System for Food Security Analysis in Lampung Province, Indonesia"
readme = "README.md"
license = {text = "MIT"}
authors = [
    {name = "Institut Teknologi Sumatera", email = "lampung-foodsec-team@itera.ac.id"}
]
maintainers = [
    {name = "Lampung Food Security Team", email = "lampung-foodsec-team@itera.ac.id"}
]
keywords = ["big-data", "food-security", "hadoop", "spark", "analytics", "lampung"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "Topic :: Scientific/Engineering :: Information Analysis",
    "Topic :: Software Development :: Libraries :: Python Modules",
]
requires-python = ">=3.8"
dependencies = [
    "pyspark",
    "findspark",
    "pandas>=2.2.0",
    "numpy>=1.24.0",
    "pyarrow",
    "python-dotenv",
    "configparser",
    "pyyaml",
    "great-expectations",
    "pandera",
    "sqlalchemy>=1.4.28,<2.0",  # Keep constraint for Airflow compatibility
    "requests",
    "pathlib2",
    "click",
    "python-dateutil",
    "pytz",
    "structlog",
    "colorlog",
    "tqdm",
    "rich",
    "tabulate",
    "tenacity",
    "backoff",
]

[project.optional-dependencies]
dev = [
    "pytest",
    "pytest-cov",
    "pytest-mock",
    "black",
    "flake8",
    "isort",
    "mypy",
    "pyright",
]
airflow = [
    "apache-airflow>=2.8.1",  # Keep constraint for SQLAlchemy compatibility
    "apache-airflow-providers-apache-spark",
    "apache-airflow-providers-apache-hive",
]
database = [
    "pymysql",
    "psycopg2-binary",
]
jupyter = [
    "ipython",
    "jupyter",
    "notebook",
    "matplotlib",
    "seaborn",
    "plotly",
]
monitoring = [
    "memory-profiler",
    "psutil",
]
serialization = [
    "orjson",
    "msgpack",
]

[project.urls]
Homepage = "https://github.com/itera/lampung-food-security"
Documentation = "https://github.com/itera/lampung-food-security/docs"
Repository = "https://github.com/itera/lampung-food-security.git"
"Bug Tracker" = "https://github.com/itera/lampung-food-security/issues"

[project.scripts]
lampung-foodsec = "src.cli:main"

[tool.setuptools.packages.find]
where = ["."]
include = ["src*"]
exclude = ["tests*", "docs*", "scripts*"]

[tool.setuptools.package-data]
"src.config" = ["*.yaml", "*.yml", "*.json"]

[tool.pyright]
include = ["src", "scripts", "dags"]
exclude = [
    "**/__pycache__",
    "**/node_modules",
    "**/.venv",
    "**/venv",
    ".git",
    "logs",
    "data",
    "output.txt"
]
defineConstant = { DEBUG = true }
stubPath = "typings"
venvPath = "."
venv = ".venv"
pythonVersion = "3.13"
pythonPlatform = "Linux"
typeCheckingMode = "basic"
useLibraryCodeForTypes = true
autoImportCompletions = true
strictListInference = true
strictDictionaryInference = true
strictSetInference = true
reportMissingImports = "warning"
reportMissingTypeStubs = "none"
reportMissingParameterType = "none"
reportUnknownParameterType = "none"
reportUnknownVariableType = "none"
reportUnknownMemberType = "none"
reportMissingTypeArgument = "none"
reportUnknownArgumentType = "none"
reportPrivateUsage = "warning"
reportConstantRedefinition = "error"
reportIncompatibleMethodOverride = "error"
reportIncompatibleVariableOverride = "error"
reportUntypedFunctionDecorator = "none"
reportUntypedClassDecorator = "none"
reportUntypedBaseClass = "none"
reportUntypedNamedTuple = "none"
reportCallInDefaultInitializer = "none"
reportUnnecessaryIsInstance = "warning"
reportUnnecessaryCast = "warning"
reportImplicitStringConcatenation = "warning"
reportUnusedImport = "warning"
reportUnusedClass = "warning"
reportUnusedFunction = "warning"
reportUnusedVariable = "warning"
reportDuplicateImport = "warning"

[tool.black]
line-length = 88
target-version = ['py38', 'py39', 'py310', 'py311', 'py312']
include = '\.pyi?$'
exclude = '''
/(
    \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | _build
  | buck-out
  | build
  | dist
  | data
  | logs
  | __pycache__
)/
'''

[tool.isort]
profile = "black"
line_length = 88
multi_line_output = 3
include_trailing_comma = true
force_grid_wrap = 0
use_parentheses = true
ensure_newline_before_comments = true
skip_glob = [
    "**/__pycache__",
    "**/venv",
    "**/.venv",
    "**/data",
    "**/logs"
]
known_first_party = ["src"]
known_third_party = [
    "pyspark",
    "airflow",
    "pandas",
    "numpy",
    "pytest",
    "click",
    "yaml",
    "sqlalchemy"
]

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = false
disallow_incomplete_defs = false
check_untyped_defs = true
disallow_untyped_decorators = false
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true
strict_equality = true
ignore_missing_imports = true
exclude = [
    "build/",
    "dist/",
    "data/",
    "logs/",
    ".venv/",
    "venv/"
]

[[tool.mypy.overrides]]
module = [
    "pyspark.*",
    "airflow.*",
    "great_expectations.*",
    "pandera.*",
    "findspark.*"
]
ignore_missing_imports = true

[tool.pytest.ini_options]
minversion = "6.0"
addopts = [
    "-ra",
    "--strict-markers",
    "--strict-config",
    "--cov=src",
    "--cov-report=html",
    "--cov-report=term-missing",
    "--cov-fail-under=80"
]
testpaths = ["tests"]
python_files = ["test_*.py", "*_test.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
markers = [
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    "integration: marks tests as integration tests",
    "unit: marks tests as unit tests",
    "spark: marks tests that require Spark",
    "hdfs: marks tests that require HDFS"
]
filterwarnings = [
    "ignore::UserWarning",
    "ignore::DeprecationWarning",
    "ignore::PendingDeprecationWarning"
]

[tool.coverage.run]
source = ["src"]
omit = [
    "*/tests/*",
    "*/test_*",
    "*/__pycache__/*",
    "*/migrations/*",
    "*/venv/*",
    "*/.venv/*"
]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "if self.debug:",
    "if settings.DEBUG",
    "raise AssertionError",
    "raise NotImplementedError",
    "if 0:",
    "if __name__ == .__main__.:",
    "class .*\\bProtocol\\):",
    "@(abc\\.)?abstractmethod"
]
show_missing = true
precision = 2

[tool.flake8]
max-line-length = 88
extend-ignore = [
    "E203",  # whitespace before ':'
    "W503",  # line break before binary operator
    "W504",  # line break after binary operator
    "E402",  # module level import not at top (needed for ETL scripts)
]
exclude = [
    ".git",
    "__pycache__",
    ".venv",
    "venv",
    "build",
    "dist",
    "data",
    "logs",
    "*.egg-info"
]
per-file-ignores = [
    "__init__.py:F401,F403",
    "scripts/*.py:F401,F403",
    "src/etl/**/*.py:E402"
]
